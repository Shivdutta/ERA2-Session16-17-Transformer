{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32646,"status":"ok","timestamp":1716740295755,"user":{"displayName":"Shiv Dutta","userId":"07673039161083621542"},"user_tz":-330},"id":"H3feyUlMOVkN","outputId":"ba0d215b-29b8-4cbf-e9f3-d8a7afe89329"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab_Notebooks/Session16_17\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/Colab_Notebooks/Session16_17"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":79270,"status":"ok","timestamp":1716740375016,"user":{"displayName":"Shiv Dutta","userId":"07673039161083621542"},"user_tz":-330},"id":"lBunYecQsUO8","outputId":"47926449-ac3d-4edc-9be7-5e29a1781ad9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torchmetrics\n","  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/868.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m686.1/868.8 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy\u003e1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n","Requirement already satisfied: packaging\u003e17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.0)\n","Requirement already satisfied: torch\u003e=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.3.0+cu121)\n","Collecting lightning-utilities\u003e=0.8.0 (from torchmetrics)\n","  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities\u003e=0.8.0-\u003etorchmetrics) (67.7.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities\u003e=0.8.0-\u003etorchmetrics) (4.11.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.10.0-\u003etorchmetrics) (3.14.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.10.0-\u003etorchmetrics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.10.0-\u003etorchmetrics) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.10.0-\u003etorchmetrics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.10.0-\u003etorchmetrics) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch\u003e=1.10.0-\u003etorchmetrics)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch\u003e=1.10.0-\u003etorchmetrics)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch\u003e=1.10.0-\u003etorchmetrics)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch\u003e=1.10.0-\u003etorchmetrics)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch\u003e=1.10.0-\u003etorchmetrics)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch\u003e=1.10.0-\u003etorchmetrics)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch\u003e=1.10.0-\u003etorchmetrics)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch\u003e=1.10.0-\u003etorchmetrics)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch\u003e=1.10.0-\u003etorchmetrics)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch\u003e=1.10.0-\u003etorchmetrics)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch\u003e=1.10.0-\u003etorchmetrics)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.10.0-\u003etorchmetrics) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107-\u003etorch\u003e=1.10.0-\u003etorchmetrics)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch\u003e=1.10.0-\u003etorchmetrics) (2.1.5)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch\u003e=1.10.0-\u003etorchmetrics) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n","Successfully installed lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 torchmetrics-1.4.0.post0\n","Collecting datasets\n","  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n","Requirement already satisfied: pyarrow\u003e=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Collecting dill\u003c0.3.9,\u003e=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n","Requirement already satisfied: requests\u003e=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm\u003e=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]\u003c=2024.3.1,\u003e=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n","Requirement already satisfied: huggingface-hub\u003e=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.3.1)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (23.2.0)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.4.1)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (6.0.5)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.9.4)\n","Requirement already satisfied: async-timeout\u003c5.0,\u003e=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (4.0.3)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.21.2-\u003edatasets) (4.11.0)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (3.7)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil\u003e=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003edatasets) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003edatasets) (2023.4)\n","Requirement already satisfied: tzdata\u003e=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003edatasets) (2024.1)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil\u003e=2.8.2-\u003epandas-\u003edatasets) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, datasets\n","Successfully installed datasets-2.19.1 dill-0.3.8 multiprocess-0.70.16 xxhash-3.4.1\n","Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.19.1)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.23.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.16.4-\u003etokenizers) (3.14.0)\n","Requirement already satisfied: fsspec\u003e=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.16.4-\u003etokenizers) (2023.6.0)\n","Requirement already satisfied: packaging\u003e=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.16.4-\u003etokenizers) (24.0)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.16.4-\u003etokenizers) (6.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.16.4-\u003etokenizers) (2.31.0)\n","Requirement already satisfied: tqdm\u003e=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.16.4-\u003etokenizers) (4.66.4)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.16.4-\u003etokenizers) (4.11.0)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub\u003c1.0,\u003e=0.16.4-\u003etokenizers) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub\u003c1.0,\u003e=0.16.4-\u003etokenizers) (3.7)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub\u003c1.0,\u003e=0.16.4-\u003etokenizers) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub\u003c1.0,\u003e=0.16.4-\u003etokenizers) (2024.2.2)\n","Collecting pytorch-lightning\n","  Downloading pytorch_lightning-2.2.5-py3-none-any.whl (802 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.3/802.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy\u003e=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.25.2)\n","Requirement already satisfied: torch\u003e=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.3.0+cu121)\n","Requirement already satisfied: tqdm\u003e=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.4)\n","Requirement already satisfied: PyYAML\u003e=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n","Requirement already satisfied: fsspec[http]\u003e=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n","Requirement already satisfied: torchmetrics\u003e=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.4.0.post0)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (24.0)\n","Requirement already satisfied: typing-extensions\u003e=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.11.0)\n","Requirement already satisfied: lightning-utilities\u003e=0.8.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.11.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]\u003e=2022.5.0-\u003epytorch-lightning) (2.31.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]\u003e=2022.5.0-\u003epytorch-lightning) (3.9.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities\u003e=0.8.0-\u003epytorch-lightning) (67.7.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.13.0-\u003epytorch-lightning) (3.14.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.13.0-\u003epytorch-lightning) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.13.0-\u003epytorch-lightning) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.13.0-\u003epytorch-lightning) (3.1.4)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.13.0-\u003epytorch-lightning) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.13.0-\u003epytorch-lightning) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.13.0-\u003epytorch-lightning) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.13.0-\u003epytorch-lightning) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.13.0-\u003epytorch-lightning) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.13.0-\u003epytorch-lightning) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.13.0-\u003epytorch-lightning) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.13.0-\u003epytorch-lightning) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.13.0-\u003epytorch-lightning) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.13.0-\u003epytorch-lightning) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.13.0-\u003epytorch-lightning) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.13.0-\u003epytorch-lightning) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107-\u003etorch\u003e=1.13.0-\u003epytorch-lightning) (12.5.40)\n","Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003e=2022.5.0-\u003epytorch-lightning) (1.3.1)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003e=2022.5.0-\u003epytorch-lightning) (23.2.0)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003e=2022.5.0-\u003epytorch-lightning) (1.4.1)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003e=2022.5.0-\u003epytorch-lightning) (6.0.5)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003e=2022.5.0-\u003epytorch-lightning) (1.9.4)\n","Requirement already satisfied: async-timeout\u003c5.0,\u003e=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003e=2022.5.0-\u003epytorch-lightning) (4.0.3)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch\u003e=1.13.0-\u003epytorch-lightning) (2.1.5)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003efsspec[http]\u003e=2022.5.0-\u003epytorch-lightning) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003efsspec[http]\u003e=2022.5.0-\u003epytorch-lightning) (3.7)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003efsspec[http]\u003e=2022.5.0-\u003epytorch-lightning) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003efsspec[http]\u003e=2022.5.0-\u003epytorch-lightning) (2024.2.2)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch\u003e=1.13.0-\u003epytorch-lightning) (1.3.0)\n","Installing collected packages: pytorch-lightning\n","Successfully installed pytorch-lightning-2.2.5\n"]}],"source":["!pip install torchmetrics\n","!pip install datasets\n","!pip install tokenizers\n","!pip install pytorch-lightning"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5239,"status":"ok","timestamp":1716740380226,"user":{"displayName":"Shiv Dutta","userId":"07673039161083621542"},"user_tz":-330},"id":"ijC3uu3nT5gV"},"outputs":[],"source":["import sys\n","import warnings\n","\n","import pytorch_lightning as pl\n","from pytorch_lightning.callbacks import ModelSummary, LearningRateMonitor, ModelCheckpoint, LearningRateFinder\n","\n","warnings.filterwarnings(\"ignore\")\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":673,"status":"ok","timestamp":1716740380889,"user":{"displayName":"Shiv Dutta","userId":"07673039161083621542"},"user_tz":-330},"id":"x0IUC5HeQJCc"},"outputs":[],"source":["from config import get_config\n","\n","cfg = get_config()\n","\n","cfg['batch_size'] = 6\n","cfg['preload'] = None\n","cfg['num_epochs'] = 20"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113},"executionInfo":{"elapsed":13362,"status":"ok","timestamp":1716740394245,"user":{"displayName":"Shiv Dutta","userId":"07673039161083621542"},"user_tz":-330},"id":"xFWQDCMrWRwQ","outputId":"4db821e6-4ceb-4389-87f0-58e8ed760f64"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6ad94d8c45a14d0999821417877b54ab","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/28.1k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cb4c21c818af4b719a7a2fc3bc93c728","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/5.73M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2355e4595987452ba8e41cf90444581f","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/32332 [00:00\u003c?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from light import LITTransformer\n","\n","model = LITTransformer(cfg)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":6924662,"status":"ok","timestamp":1716748557708,"user":{"displayName":"Shiv Dutta","userId":"07673039161083621542"},"user_tz":-330},"id":"b6vE3PV0T7TG"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:Trainer already configured with model summary callbacks: [\u003cclass 'pytorch_lightning.callbacks.model_summary.ModelSummary'\u003e]. Skipping setting a default `ModelSummary` callback.\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.utilities.rank_zero:`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n","INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"name":"stdout","output_type":"stream","text":["Max length of source sentence: 309\n","Max length of target sentence: 274\n"]},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.callbacks.model_summary:\n","    | Name                                                  | Type                    | Params\n","----------------------------------------------------------------------------------------------------\n","0   | model                                                 | Transformer             | 75.1 M\n","1   | model.encoder                                         | Encoder                 | 18.9 M\n","2   | model.encoder.layers                                  | ModuleList              | 18.9 M\n","3   | model.encoder.layers.0                                | EncoderBlock            | 3.1 M \n","4   | model.encoder.layers.0.self_attention_block           | MultiHeadAttentionBlock | 1.0 M \n","5   | model.encoder.layers.0.self_attention_block.w_q       | Linear                  | 262 K \n","6   | model.encoder.layers.0.self_attention_block.w_k       | Linear                  | 262 K \n","7   | model.encoder.layers.0.self_attention_block.w_v       | Linear                  | 262 K \n","8   | model.encoder.layers.0.self_attention_block.w_o       | Linear                  | 262 K \n","9   | model.encoder.layers.0.self_attention_block.dropout   | Dropout                 | 0     \n","10  | model.encoder.layers.0.feed_forward_block             | FeedForwardBlock        | 2.1 M \n","11  | model.encoder.layers.0.feed_forward_block.linear_1    | Linear                  | 1.1 M \n","12  | model.encoder.layers.0.feed_forward_block.dropout     | Dropout                 | 0     \n","13  | model.encoder.layers.0.feed_forward_block.linear_2    | Linear                  | 1.0 M \n","14  | model.encoder.layers.0.residual_connections           | ModuleList              | 4     \n","15  | model.encoder.layers.0.residual_connections.0         | ResidualConnection      | 2     \n","16  | model.encoder.layers.0.residual_connections.0.dropout | Dropout                 | 0     \n","17  | model.encoder.layers.0.residual_connections.0.norm    | LayerNormalization      | 2     \n","18  | model.encoder.layers.0.residual_connections.1         | ResidualConnection      | 2     \n","19  | model.encoder.layers.0.residual_connections.1.dropout | Dropout                 | 0     \n","20  | model.encoder.layers.0.residual_connections.1.norm    | LayerNormalization      | 2     \n","21  | model.encoder.layers.1                                | EncoderBlock            | 3.1 M \n","22  | model.encoder.layers.1.self_attention_block           | MultiHeadAttentionBlock | 1.0 M \n","23  | model.encoder.layers.1.self_attention_block.w_q       | Linear                  | 262 K \n","24  | model.encoder.layers.1.self_attention_block.w_k       | Linear                  | 262 K \n","25  | model.encoder.layers.1.self_attention_block.w_v       | Linear                  | 262 K \n","26  | model.encoder.layers.1.self_attention_block.w_o       | Linear                  | 262 K \n","27  | model.encoder.layers.1.self_attention_block.dropout   | Dropout                 | 0     \n","28  | model.encoder.layers.1.feed_forward_block             | FeedForwardBlock        | 2.1 M \n","29  | model.encoder.layers.1.feed_forward_block.linear_1    | Linear                  | 1.1 M \n","30  | model.encoder.layers.1.feed_forward_block.dropout     | Dropout                 | 0     \n","31  | model.encoder.layers.1.feed_forward_block.linear_2    | Linear                  | 1.0 M \n","32  | model.encoder.layers.1.residual_connections           | ModuleList              | 4     \n","33  | model.encoder.layers.1.residual_connections.0         | ResidualConnection      | 2     \n","34  | model.encoder.layers.1.residual_connections.0.dropout | Dropout                 | 0     \n","35  | model.encoder.layers.1.residual_connections.0.norm    | LayerNormalization      | 2     \n","36  | model.encoder.layers.1.residual_connections.1         | ResidualConnection      | 2     \n","37  | model.encoder.layers.1.residual_connections.1.dropout | Dropout                 | 0     \n","38  | model.encoder.layers.1.residual_connections.1.norm    | LayerNormalization      | 2     \n","39  | model.encoder.layers.2                                | EncoderBlock            | 3.1 M \n","40  | model.encoder.layers.2.self_attention_block           | MultiHeadAttentionBlock | 1.0 M \n","41  | model.encoder.layers.2.self_attention_block.w_q       | Linear                  | 262 K \n","42  | model.encoder.layers.2.self_attention_block.w_k       | Linear                  | 262 K \n","43  | model.encoder.layers.2.self_attention_block.w_v       | Linear                  | 262 K \n","44  | model.encoder.layers.2.self_attention_block.w_o       | Linear                  | 262 K \n","45  | model.encoder.layers.2.self_attention_block.dropout   | Dropout                 | 0     \n","46  | model.encoder.layers.2.feed_forward_block             | FeedForwardBlock        | 2.1 M \n","47  | model.encoder.layers.2.feed_forward_block.linear_1    | Linear                  | 1.1 M \n","48  | model.encoder.layers.2.feed_forward_block.dropout     | Dropout                 | 0     \n","49  | model.encoder.layers.2.feed_forward_block.linear_2    | Linear                  | 1.0 M \n","50  | model.encoder.layers.2.residual_connections           | ModuleList              | 4     \n","51  | model.encoder.layers.2.residual_connections.0         | ResidualConnection      | 2     \n","52  | model.encoder.layers.2.residual_connections.0.dropout | Dropout                 | 0     \n","53  | model.encoder.layers.2.residual_connections.0.norm    | LayerNormalization      | 2     \n","54  | model.encoder.layers.2.residual_connections.1         | ResidualConnection      | 2     \n","55  | model.encoder.layers.2.residual_connections.1.dropout | Dropout                 | 0     \n","56  | model.encoder.layers.2.residual_connections.1.norm    | LayerNormalization      | 2     \n","57  | model.encoder.layers.3                                | EncoderBlock            | 3.1 M \n","58  | model.encoder.layers.3.self_attention_block           | MultiHeadAttentionBlock | 1.0 M \n","59  | model.encoder.layers.3.self_attention_block.w_q       | Linear                  | 262 K \n","60  | model.encoder.layers.3.self_attention_block.w_k       | Linear                  | 262 K \n","61  | model.encoder.layers.3.self_attention_block.w_v       | Linear                  | 262 K \n","62  | model.encoder.layers.3.self_attention_block.w_o       | Linear                  | 262 K \n","63  | model.encoder.layers.3.self_attention_block.dropout   | Dropout                 | 0     \n","64  | model.encoder.layers.3.feed_forward_block             | FeedForwardBlock        | 2.1 M \n","65  | model.encoder.layers.3.feed_forward_block.linear_1    | Linear                  | 1.1 M \n","66  | model.encoder.layers.3.feed_forward_block.dropout     | Dropout                 | 0     \n","67  | model.encoder.layers.3.feed_forward_block.linear_2    | Linear                  | 1.0 M \n","68  | model.encoder.layers.3.residual_connections           | ModuleList              | 4     \n","69  | model.encoder.layers.3.residual_connections.0         | ResidualConnection      | 2     \n","70  | model.encoder.layers.3.residual_connections.0.dropout | Dropout                 | 0     \n","71  | model.encoder.layers.3.residual_connections.0.norm    | LayerNormalization      | 2     \n","72  | model.encoder.layers.3.residual_connections.1         | ResidualConnection      | 2     \n","73  | model.encoder.layers.3.residual_connections.1.dropout | Dropout                 | 0     \n","74  | model.encoder.layers.3.residual_connections.1.norm    | LayerNormalization      | 2     \n","75  | model.encoder.layers.4                                | EncoderBlock            | 3.1 M \n","76  | model.encoder.layers.4.self_attention_block           | MultiHeadAttentionBlock | 1.0 M \n","77  | model.encoder.layers.4.self_attention_block.w_q       | Linear                  | 262 K \n","78  | model.encoder.layers.4.self_attention_block.w_k       | Linear                  | 262 K \n","79  | model.encoder.layers.4.self_attention_block.w_v       | Linear                  | 262 K \n","80  | model.encoder.layers.4.self_attention_block.w_o       | Linear                  | 262 K \n","81  | model.encoder.layers.4.self_attention_block.dropout   | Dropout                 | 0     \n","82  | model.encoder.layers.4.feed_forward_block             | FeedForwardBlock        | 2.1 M \n","83  | model.encoder.layers.4.feed_forward_block.linear_1    | Linear                  | 1.1 M \n","84  | model.encoder.layers.4.feed_forward_block.dropout     | Dropout                 | 0     \n","85  | model.encoder.layers.4.feed_forward_block.linear_2    | Linear                  | 1.0 M \n","86  | model.encoder.layers.4.residual_connections           | ModuleList              | 4     \n","87  | model.encoder.layers.4.residual_connections.0         | ResidualConnection      | 2     \n","88  | model.encoder.layers.4.residual_connections.0.dropout | Dropout                 | 0     \n","89  | model.encoder.layers.4.residual_connections.0.norm    | LayerNormalization      | 2     \n","90  | model.encoder.layers.4.residual_connections.1         | ResidualConnection      | 2     \n","91  | model.encoder.layers.4.residual_connections.1.dropout | Dropout                 | 0     \n","92  | model.encoder.layers.4.residual_connections.1.norm    | LayerNormalization      | 2     \n","93  | model.encoder.layers.5                                | EncoderBlock            | 3.1 M \n","94  | model.encoder.layers.5.self_attention_block           | MultiHeadAttentionBlock | 1.0 M \n","95  | model.encoder.layers.5.self_attention_block.w_q       | Linear                  | 262 K \n","96  | model.encoder.layers.5.self_attention_block.w_k       | Linear                  | 262 K \n","97  | model.encoder.layers.5.self_attention_block.w_v       | Linear                  | 262 K \n","98  | model.encoder.layers.5.self_attention_block.w_o       | Linear                  | 262 K \n","99  | model.encoder.layers.5.self_attention_block.dropout   | Dropout                 | 0     \n","100 | model.encoder.layers.5.feed_forward_block             | FeedForwardBlock        | 2.1 M \n","101 | model.encoder.layers.5.feed_forward_block.linear_1    | Linear                  | 1.1 M \n","102 | model.encoder.layers.5.feed_forward_block.dropout     | Dropout                 | 0     \n","103 | model.encoder.layers.5.feed_forward_block.linear_2    | Linear                  | 1.0 M \n","104 | model.encoder.layers.5.residual_connections           | ModuleList              | 4     \n","105 | model.encoder.layers.5.residual_connections.0         | ResidualConnection      | 2     \n","106 | model.encoder.layers.5.residual_connections.0.dropout | Dropout                 | 0     \n","107 | model.encoder.layers.5.residual_connections.0.norm    | LayerNormalization      | 2     \n","108 | model.encoder.layers.5.residual_connections.1         | ResidualConnection      | 2     \n","109 | model.encoder.layers.5.residual_connections.1.dropout | Dropout                 | 0     \n","110 | model.encoder.layers.5.residual_connections.1.norm    | LayerNormalization      | 2     \n","111 | model.encoder.norm                                    | LayerNormalization      | 2     \n","112 | model.decoder                                         | Decoder                 | 25.2 M\n","113 | model.decoder.layers                                  | ModuleList              | 25.2 M\n","114 | model.decoder.layers.0                                | DecoderBlock            | 4.2 M \n","115 | model.decoder.layers.0.self_attention_block           | MultiHeadAttentionBlock | 1.0 M \n","116 | model.decoder.layers.0.self_attention_block.w_q       | Linear                  | 262 K \n","117 | model.decoder.layers.0.self_attention_block.w_k       | Linear                  | 262 K \n","118 | model.decoder.layers.0.self_attention_block.w_v       | Linear                  | 262 K \n","119 | model.decoder.layers.0.self_attention_block.w_o       | Linear                  | 262 K \n","120 | model.decoder.layers.0.self_attention_block.dropout   | Dropout                 | 0     \n","121 | model.decoder.layers.0.cross_attention_block          | MultiHeadAttentionBlock | 1.0 M \n","122 | model.decoder.layers.0.cross_attention_block.w_q      | Linear                  | 262 K \n","123 | model.decoder.layers.0.cross_attention_block.w_k      | Linear                  | 262 K \n","124 | model.decoder.layers.0.cross_attention_block.w_v      | Linear                  | 262 K \n","125 | model.decoder.layers.0.cross_attention_block.w_o      | Linear                  | 262 K \n","126 | model.decoder.layers.0.cross_attention_block.dropout  | Dropout                 | 0     \n","127 | model.decoder.layers.0.feed_forward_block             | FeedForwardBlock        | 2.1 M \n","128 | model.decoder.layers.0.feed_forward_block.linear_1    | Linear                  | 1.1 M \n","129 | model.decoder.layers.0.feed_forward_block.dropout     | Dropout                 | 0     \n","130 | model.decoder.layers.0.feed_forward_block.linear_2    | Linear                  | 1.0 M \n","131 | model.decoder.layers.0.residual_connections           | ModuleList              | 6     \n","132 | model.decoder.layers.0.residual_connections.0         | ResidualConnection      | 2     \n","133 | model.decoder.layers.0.residual_connections.0.dropout | Dropout                 | 0     \n","134 | model.decoder.layers.0.residual_connections.0.norm    | LayerNormalization      | 2     \n","135 | model.decoder.layers.0.residual_connections.1         | ResidualConnection      | 2     \n","136 | model.decoder.layers.0.residual_connections.1.dropout | Dropout                 | 0     \n","137 | model.decoder.layers.0.residual_connections.1.norm    | LayerNormalization      | 2     \n","138 | model.decoder.layers.0.residual_connections.2         | ResidualConnection      | 2     \n","139 | model.decoder.layers.0.residual_connections.2.dropout | Dropout                 | 0     \n","140 | model.decoder.layers.0.residual_connections.2.norm    | LayerNormalization      | 2     \n","141 | model.decoder.layers.1                                | DecoderBlock            | 4.2 M \n","142 | model.decoder.layers.1.self_attention_block           | MultiHeadAttentionBlock | 1.0 M \n","143 | model.decoder.layers.1.self_attention_block.w_q       | Linear                  | 262 K \n","144 | model.decoder.layers.1.self_attention_block.w_k       | Linear                  | 262 K \n","145 | model.decoder.layers.1.self_attention_block.w_v       | Linear                  | 262 K \n","146 | model.decoder.layers.1.self_attention_block.w_o       | Linear                  | 262 K \n","147 | model.decoder.layers.1.self_attention_block.dropout   | Dropout                 | 0     \n","148 | model.decoder.layers.1.cross_attention_block          | MultiHeadAttentionBlock | 1.0 M \n","149 | model.decoder.layers.1.cross_attention_block.w_q      | Linear                  | 262 K \n","150 | model.decoder.layers.1.cross_attention_block.w_k      | Linear                  | 262 K \n","151 | model.decoder.layers.1.cross_attention_block.w_v      | Linear                  | 262 K \n","152 | model.decoder.layers.1.cross_attention_block.w_o      | Linear                  | 262 K \n","153 | model.decoder.layers.1.cross_attention_block.dropout  | Dropout                 | 0     \n","154 | model.decoder.layers.1.feed_forward_block             | FeedForwardBlock        | 2.1 M \n","155 | model.decoder.layers.1.feed_forward_block.linear_1    | Linear                  | 1.1 M \n","156 | model.decoder.layers.1.feed_forward_block.dropout     | Dropout                 | 0     \n","157 | model.decoder.layers.1.feed_forward_block.linear_2    | Linear                  | 1.0 M \n","158 | model.decoder.layers.1.residual_connections           | ModuleList              | 6     \n","159 | model.decoder.layers.1.residual_connections.0         | ResidualConnection      | 2     \n","160 | model.decoder.layers.1.residual_connections.0.dropout | Dropout                 | 0     \n","161 | model.decoder.layers.1.residual_connections.0.norm    | LayerNormalization      | 2     \n","162 | model.decoder.layers.1.residual_connections.1         | ResidualConnection      | 2     \n","163 | model.decoder.layers.1.residual_connections.1.dropout | Dropout                 | 0     \n","164 | model.decoder.layers.1.residual_connections.1.norm    | LayerNormalization      | 2     \n","165 | model.decoder.layers.1.residual_connections.2         | ResidualConnection      | 2     \n","166 | model.decoder.layers.1.residual_connections.2.dropout | Dropout                 | 0     \n","167 | model.decoder.layers.1.residual_connections.2.norm    | LayerNormalization      | 2     \n","168 | model.decoder.layers.2                                | DecoderBlock            | 4.2 M \n","169 | model.decoder.layers.2.self_attention_block           | MultiHeadAttentionBlock | 1.0 M \n","170 | model.decoder.layers.2.self_attention_block.w_q       | Linear                  | 262 K \n","171 | model.decoder.layers.2.self_attention_block.w_k       | Linear                  | 262 K \n","172 | model.decoder.layers.2.self_attention_block.w_v       | Linear                  | 262 K \n","173 | model.decoder.layers.2.self_attention_block.w_o       | Linear                  | 262 K \n","174 | model.decoder.layers.2.self_attention_block.dropout   | Dropout                 | 0     \n","175 | model.decoder.layers.2.cross_attention_block          | MultiHeadAttentionBlock | 1.0 M \n","176 | model.decoder.layers.2.cross_attention_block.w_q      | Linear                  | 262 K \n","177 | model.decoder.layers.2.cross_attention_block.w_k      | Linear                  | 262 K \n","178 | model.decoder.layers.2.cross_attention_block.w_v      | Linear                  | 262 K \n","179 | model.decoder.layers.2.cross_attention_block.w_o      | Linear                  | 262 K \n","180 | model.decoder.layers.2.cross_attention_block.dropout  | Dropout                 | 0     \n","181 | model.decoder.layers.2.feed_forward_block             | FeedForwardBlock        | 2.1 M \n","182 | model.decoder.layers.2.feed_forward_block.linear_1    | Linear                  | 1.1 M \n","183 | model.decoder.layers.2.feed_forward_block.dropout     | Dropout                 | 0     \n","184 | model.decoder.layers.2.feed_forward_block.linear_2    | Linear                  | 1.0 M \n","185 | model.decoder.layers.2.residual_connections           | ModuleList              | 6     \n","186 | model.decoder.layers.2.residual_connections.0         | ResidualConnection      | 2     \n","187 | model.decoder.layers.2.residual_connections.0.dropout | Dropout                 | 0     \n","188 | model.decoder.layers.2.residual_connections.0.norm    | LayerNormalization      | 2     \n","189 | model.decoder.layers.2.residual_connections.1         | ResidualConnection      | 2     \n","190 | model.decoder.layers.2.residual_connections.1.dropout | Dropout                 | 0     \n","191 | model.decoder.layers.2.residual_connections.1.norm    | LayerNormalization      | 2     \n","192 | model.decoder.layers.2.residual_connections.2         | ResidualConnection      | 2     \n","193 | model.decoder.layers.2.residual_connections.2.dropout | Dropout                 | 0     \n","194 | model.decoder.layers.2.residual_connections.2.norm    | LayerNormalization      | 2     \n","195 | model.decoder.layers.3                                | DecoderBlock            | 4.2 M \n","196 | model.decoder.layers.3.self_attention_block           | MultiHeadAttentionBlock | 1.0 M \n","197 | model.decoder.layers.3.self_attention_block.w_q       | Linear                  | 262 K \n","198 | model.decoder.layers.3.self_attention_block.w_k       | Linear                  | 262 K \n","199 | model.decoder.layers.3.self_attention_block.w_v       | Linear                  | 262 K \n","200 | model.decoder.layers.3.self_attention_block.w_o       | Linear                  | 262 K \n","201 | model.decoder.layers.3.self_attention_block.dropout   | Dropout                 | 0     \n","202 | model.decoder.layers.3.cross_attention_block          | MultiHeadAttentionBlock | 1.0 M \n","203 | model.decoder.layers.3.cross_attention_block.w_q      | Linear                  | 262 K \n","204 | model.decoder.layers.3.cross_attention_block.w_k      | Linear                  | 262 K \n","205 | model.decoder.layers.3.cross_attention_block.w_v      | Linear                  | 262 K \n","206 | model.decoder.layers.3.cross_attention_block.w_o      | Linear                  | 262 K \n","207 | model.decoder.layers.3.cross_attention_block.dropout  | Dropout                 | 0     \n","208 | model.decoder.layers.3.feed_forward_block             | FeedForwardBlock        | 2.1 M \n","209 | model.decoder.layers.3.feed_forward_block.linear_1    | Linear                  | 1.1 M \n","210 | model.decoder.layers.3.feed_forward_block.dropout     | Dropout                 | 0     \n","211 | model.decoder.layers.3.feed_forward_block.linear_2    | Linear                  | 1.0 M \n","212 | model.decoder.layers.3.residual_connections           | ModuleList              | 6     \n","213 | model.decoder.layers.3.residual_connections.0         | ResidualConnection      | 2     \n","214 | model.decoder.layers.3.residual_connections.0.dropout | Dropout                 | 0     \n","215 | model.decoder.layers.3.residual_connections.0.norm    | LayerNormalization      | 2     \n","216 | model.decoder.layers.3.residual_connections.1         | ResidualConnection      | 2     \n","217 | model.decoder.layers.3.residual_connections.1.dropout | Dropout                 | 0     \n","218 | model.decoder.layers.3.residual_connections.1.norm    | LayerNormalization      | 2     \n","219 | model.decoder.layers.3.residual_connections.2         | ResidualConnection      | 2     \n","220 | model.decoder.layers.3.residual_connections.2.dropout | Dropout                 | 0     \n","221 | model.decoder.layers.3.residual_connections.2.norm    | LayerNormalization      | 2     \n","222 | model.decoder.layers.4                                | DecoderBlock            | 4.2 M \n","223 | model.decoder.layers.4.self_attention_block           | MultiHeadAttentionBlock | 1.0 M \n","224 | model.decoder.layers.4.self_attention_block.w_q       | Linear                  | 262 K \n","225 | model.decoder.layers.4.self_attention_block.w_k       | Linear                  | 262 K \n","226 | model.decoder.layers.4.self_attention_block.w_v       | Linear                  | 262 K \n","227 | model.decoder.layers.4.self_attention_block.w_o       | Linear                  | 262 K \n","228 | model.decoder.layers.4.self_attention_block.dropout   | Dropout                 | 0     \n","229 | model.decoder.layers.4.cross_attention_block          | MultiHeadAttentionBlock | 1.0 M \n","230 | model.decoder.layers.4.cross_attention_block.w_q      | Linear                  | 262 K \n","231 | model.decoder.layers.4.cross_attention_block.w_k      | Linear                  | 262 K \n","232 | model.decoder.layers.4.cross_attention_block.w_v      | Linear                  | 262 K \n","233 | model.decoder.layers.4.cross_attention_block.w_o      | Linear                  | 262 K \n","234 | model.decoder.layers.4.cross_attention_block.dropout  | Dropout                 | 0     \n","235 | model.decoder.layers.4.feed_forward_block             | FeedForwardBlock        | 2.1 M \n","236 | model.decoder.layers.4.feed_forward_block.linear_1    | Linear                  | 1.1 M \n","237 | model.decoder.layers.4.feed_forward_block.dropout     | Dropout                 | 0     \n","238 | model.decoder.layers.4.feed_forward_block.linear_2    | Linear                  | 1.0 M \n","239 | model.decoder.layers.4.residual_connections           | ModuleList              | 6     \n","240 | model.decoder.layers.4.residual_connections.0         | ResidualConnection      | 2     \n","241 | model.decoder.layers.4.residual_connections.0.dropout | Dropout                 | 0     \n","242 | model.decoder.layers.4.residual_connections.0.norm    | LayerNormalization      | 2     \n","243 | model.decoder.layers.4.residual_connections.1         | ResidualConnection      | 2     \n","244 | model.decoder.layers.4.residual_connections.1.dropout | Dropout                 | 0     \n","245 | model.decoder.layers.4.residual_connections.1.norm    | LayerNormalization      | 2     \n","246 | model.decoder.layers.4.residual_connections.2         | ResidualConnection      | 2     \n","247 | model.decoder.layers.4.residual_connections.2.dropout | Dropout                 | 0     \n","248 | model.decoder.layers.4.residual_connections.2.norm    | LayerNormalization      | 2     \n","249 | model.decoder.layers.5                                | DecoderBlock            | 4.2 M \n","250 | model.decoder.layers.5.self_attention_block           | MultiHeadAttentionBlock | 1.0 M \n","251 | model.decoder.layers.5.self_attention_block.w_q       | Linear                  | 262 K \n","252 | model.decoder.layers.5.self_attention_block.w_k       | Linear                  | 262 K \n","253 | model.decoder.layers.5.self_attention_block.w_v       | Linear                  | 262 K \n","254 | model.decoder.layers.5.self_attention_block.w_o       | Linear                  | 262 K \n","255 | model.decoder.layers.5.self_attention_block.dropout   | Dropout                 | 0     \n","256 | model.decoder.layers.5.cross_attention_block          | MultiHeadAttentionBlock | 1.0 M \n","257 | model.decoder.layers.5.cross_attention_block.w_q      | Linear                  | 262 K \n","258 | model.decoder.layers.5.cross_attention_block.w_k      | Linear                  | 262 K \n","259 | model.decoder.layers.5.cross_attention_block.w_v      | Linear                  | 262 K \n","260 | model.decoder.layers.5.cross_attention_block.w_o      | Linear                  | 262 K \n","261 | model.decoder.layers.5.cross_attention_block.dropout  | Dropout                 | 0     \n","262 | model.decoder.layers.5.feed_forward_block             | FeedForwardBlock        | 2.1 M \n","263 | model.decoder.layers.5.feed_forward_block.linear_1    | Linear                  | 1.1 M \n","264 | model.decoder.layers.5.feed_forward_block.dropout     | Dropout                 | 0     \n","265 | model.decoder.layers.5.feed_forward_block.linear_2    | Linear                  | 1.0 M \n","266 | model.decoder.layers.5.residual_connections           | ModuleList              | 6     \n","267 | model.decoder.layers.5.residual_connections.0         | ResidualConnection      | 2     \n","268 | model.decoder.layers.5.residual_connections.0.dropout | Dropout                 | 0     \n","269 | model.decoder.layers.5.residual_connections.0.norm    | LayerNormalization      | 2     \n","270 | model.decoder.layers.5.residual_connections.1         | ResidualConnection      | 2     \n","271 | model.decoder.layers.5.residual_connections.1.dropout | Dropout                 | 0     \n","272 | model.decoder.layers.5.residual_connections.1.norm    | LayerNormalization      | 2     \n","273 | model.decoder.layers.5.residual_connections.2         | ResidualConnection      | 2     \n","274 | model.decoder.layers.5.residual_connections.2.dropout | Dropout                 | 0     \n","275 | model.decoder.layers.5.residual_connections.2.norm    | LayerNormalization      | 2     \n","276 | model.decoder.norm                                    | LayerNormalization      | 2     \n","277 | model.src_embed                                       | InputEmbeddings         | 8.0 M \n","278 | model.src_embed.embedding                             | Embedding               | 8.0 M \n","279 | model.tgt_embed                                       | InputEmbeddings         | 11.5 M\n","280 | model.tgt_embed.embedding                             | Embedding               | 11.5 M\n","281 | model.src_pos                                         | PositionalEncoding      | 0     \n","282 | model.src_pos.dropout                                 | Dropout                 | 0     \n","283 | model.tgt_pos                                         | PositionalEncoding      | 0     \n","284 | model.tgt_pos.dropout                                 | Dropout                 | 0     \n","285 | model.projection_layer                                | ProjectionLayer         | 11.5 M\n","286 | model.projection_layer.proj                           | Linear                  | 11.5 M\n","----------------------------------------------------------------------------------------------------\n","75.1 M    Trainable params\n","0         Non-trainable params\n","75.1 M    Total params\n","300.532   Total estimated model params size (MB)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d7f08643067f490ca575b457bea6d9f3","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:Transformer:    SOURCE: This becomes uninteresting, however, after a time, and so you put on your hat and stroll out into the garden.\n","INFO:Transformer:    TARGET: Dopo un certo tempo, nella camera da letto non trovate alcun interesse, e vi mettete il cappello per andarvene in giardino.\n","INFO:Transformer: PREDICTED: sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata finì finì finì finì finì sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata compierlo compierlo compierlo sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata finì finì finì sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata compierlo compierlo compierlo compierlo compierlo compierlo sparpagliata sparpagliata sparpagliata finì finì finì finì finì finì sparpagliata finì finì finì finì finì compierlo finì compierlo finì finì compierlo finì finì finì finì finì finì finì finì finì finì finì finì finì finì finì finì sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata finì finì finì sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata finì finì sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata finì finì finì finì finì finì finì finì finì sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata sparpagliata\n","INFO:Transformer:--------------------\n","INFO:Transformer:  \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f347a85b87a4455f831360a2b6de35eb","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Loss Mean - 6.2374653816223145\n","Loss Mean - 5.555856704711914\n","Loss Mean - 5.210582256317139\n","Loss Mean - 4.917515277862549\n","Loss Mean - 4.65082311630249\n","Loss Mean - 4.395579814910889\n","Loss Mean - 4.146484375\n","Loss Mean - 3.9090592861175537\n","Loss Mean - 3.6732118129730225\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2ff59ad63c54434daf5d713ecfc7cbbc","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:Transformer:    SOURCE: She seemed the emblem of my past life; and here I was now to array myself to meet, the dread, but adored, type of my unknown future day.\n","INFO:Transformer:    TARGET: Ella mi pareva l'emblema della mia vita passata, e colui dal quale presto stavo per andare, il tipo temuto ma adorato, della mia vita futura.\n","INFO:Transformer: PREDICTED: Pareva che la mia vita fosse stata ricca , e che mi di farla amare ogni giorno , ma la mia anima era più nobile e più elegante .\n","INFO:Transformer:--------------------\n","INFO:Transformer:  \n","INFO:pytorch_lightning.utilities.rank_zero:Epoch 9, global step 48500: 'train_loss' reached 3.67321 (best 3.67321), saving model to '/content/drive/MyDrive/Colab_Notebooks/Session16_17/lightning_logs/version_3/checkpoints/epoch=9-step=48500.ckpt' as top 1\n"]},{"name":"stdout","output_type":"stream","text":["Loss Mean - 3.452518939971924\n"]},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n"]}],"source":["# Monitor Learning rate while training to verify correct implementation of OCP\n","lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n","\n","# Save the last best model based on validation loss\n","checkpoint_callback = ModelCheckpoint(\n","    save_top_k=1,\n","    verbose=True,\n","    monitor='train_loss',\n","    mode='min',\n",")\n","\n","# Define trainer for model training\n","trainer = pl.Trainer(\n","    callbacks=[ModelSummary(max_depth=-1), lr_monitor, checkpoint_callback],\n","    max_epochs = 20,\n","    limit_val_batches=1,\n","    check_val_every_n_epoch=5,\n","    num_sanity_val_steps=1\n",")\n","\n","# Train the Model\n","trainer.fit(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":34},"id":"NA1MpMqmXcLT"},"outputs":[{"data":{"application/javascript":["\n","        (async () =\u003e {\n","            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n","            url.searchParams.set('tensorboardColab', 'true');\n","            const iframe = document.createElement('iframe');\n","            iframe.src = url;\n","            iframe.setAttribute('width', '100%');\n","            iframe.setAttribute('height', '800');\n","            iframe.setAttribute('frameborder', 0);\n","            document.body.appendChild(iframe);\n","        })();\n","    "],"text/plain":["\u003cIPython.core.display.Javascript object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["# start tensorboard\n","%load_ext tensorboard\n","%tensorboard --logdir lightning_logs/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Alulvw6CRn9u"},"outputs":[],"source":["# Save the model\n","trainer.save_checkpoint(\"transformer.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vZ9Fy7_amRfw"},"outputs":[],"source":["trainer.validate()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0126d382270a42b89868ac844923d5ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03fdabaa802b4150879de64332bcbbae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d39c3e777f64391b1524dd43efc5dc2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0eff4dd905f24570b871c0dca2244852":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_de0e4b73aaa8431ab06566f76d40d9c0","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_988550c07d8e427f9a3e4716327ab82c","value":1}},"18d3593f4ac340e9b832ae3a54621497":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1bfe8387c7fb4389b7ac80f653292c4a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ffa9ae1f722483daddadf148ec71e88":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"2355e4595987452ba8e41cf90444581f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fe5d151a7a3e478f96cee0a7def507b2","IPY_MODEL_6bbc0fc64317407e916eeeaebe68e7de","IPY_MODEL_bf14ba927e8a4b3d83cad511d230098c"],"layout":"IPY_MODEL_65ea58aaba244386afa5bbaa7c1a899c"}},"2610f06efce144e095f515834400e2ce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"274c613919794a9f832a836eae2be908":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ff59ad63c54434daf5d713ecfc7cbbc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cadebe445202422681ebdf9fb68fe213","IPY_MODEL_3e6b3ef4ddc841f8939bd4b1e500d072","IPY_MODEL_3ef87841cae04e759bf0236fc068fbbd"],"layout":"IPY_MODEL_6551e2c7bb034a7d8fb5bdddb6fd1ec1"}},"31bfb35ba4254018ba5dd8c52c70cb63":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d5d95409f264505a69cddcf9927420d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4aefd653ffba447abe00a051eceb192c","placeholder":"​","style":"IPY_MODEL_dbd61dd727754e3ba398a50b6510d187","value":" 5.73M/5.73M [00:00\u0026lt;00:00, 17.1MB/s]"}},"3e6b3ef4ddc841f8939bd4b1e500d072":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_7525c6ac0c2d48d0800ca52fabf9d8b8","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b012a2ea780d4e26a53681bfcbf1e1fb","value":1}},"3e7a86cb92a64a6cb0e61cf3f2f75f12":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6df9694a27084019ba1cbde01ad4095b","placeholder":"​","style":"IPY_MODEL_18d3593f4ac340e9b832ae3a54621497","value":" 1/1 [00:04\u0026lt;00:00,  0.22it/s]"}},"3ef87841cae04e759bf0236fc068fbbd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb7016caa05a4c8689a3ab78a579f76a","placeholder":"​","style":"IPY_MODEL_b21bdaf1dbdc4a9c8b5825f928fee7d2","value":" 1/1 [00:00\u0026lt;00:00,  2.70it/s]"}},"433eb409262e41919d6814d4d66f42b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c497743d7b141eabe74c0dfbe9c2541","placeholder":"​","style":"IPY_MODEL_0126d382270a42b89868ac844923d5ad","value":" 4850/4850 [13:37\u0026lt;00:00,  5.94it/s, v_num=3, train_loss=3.450, validation cer=0.709, validation wer=1.120, validation BLEU=0.000]"}},"45bbfcfaa9c84526ab27f13f8556a07f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"47fd974cd1db4b13bf28bcbb9d44ba8b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4aefd653ffba447abe00a051eceb192c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c5410d301d442df950e84b7985891e0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ef3d9b65fbd4767b95c1840842520d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6335f582d21d46dbb3481c76d27de350":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6551e2c7bb034a7d8fb5bdddb6fd1ec1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"65ea58aaba244386afa5bbaa7c1a899c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6741ad97ba0d49369f48babce42d2550":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67ac9924dc92416ea28c4e6565192b6f","placeholder":"​","style":"IPY_MODEL_0d39c3e777f64391b1524dd43efc5dc2","value":"Epoch 9: 100%"}},"67ac9924dc92416ea28c4e6565192b6f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ad94d8c45a14d0999821417877b54ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_83127a7e54b94ac4b7a0d4c37f54b3bb","IPY_MODEL_c617b8a685c042c698f5a5543d63b24b","IPY_MODEL_9a8ef2e15a3d41fe97a422c40fb345a6"],"layout":"IPY_MODEL_47fd974cd1db4b13bf28bcbb9d44ba8b"}},"6bbc0fc64317407e916eeeaebe68e7de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a67f96ed129243ceb8c862bf8310e4c5","max":32332,"min":0,"orientation":"horizontal","style":"IPY_MODEL_274c613919794a9f832a836eae2be908","value":32332}},"6c497743d7b141eabe74c0dfbe9c2541":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ccc4cf179b94a48875cc8e7d336b3cf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6df9694a27084019ba1cbde01ad4095b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7525c6ac0c2d48d0800ca52fabf9d8b8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75426bb858944ebf875e40ceefeee0a3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ccc4cf179b94a48875cc8e7d336b3cf","max":5726189,"min":0,"orientation":"horizontal","style":"IPY_MODEL_81ecddb98d7643da9afe0e1fa03a8193","value":5726189}},"81ecddb98d7643da9afe0e1fa03a8193":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"83127a7e54b94ac4b7a0d4c37f54b3bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac8e81b943844f639839b06f8da98586","placeholder":"​","style":"IPY_MODEL_ede7e31213ae422a8bda27a71bff15dd","value":"Downloading readme: 100%"}},"8e4c2083395344fe8175358d2a72c78b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"988550c07d8e427f9a3e4716327ab82c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9a59ce8cfffe438296419cb4a4082537":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9766e4aa3804feba44f7eaf99b4d349","placeholder":"​","style":"IPY_MODEL_9e32449cd53b47f7bfbea13e90ff197a","value":"Sanity Checking DataLoader 0: 100%"}},"9a8ef2e15a3d41fe97a422c40fb345a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2610f06efce144e095f515834400e2ce","placeholder":"​","style":"IPY_MODEL_03fdabaa802b4150879de64332bcbbae","value":" 28.1k/28.1k [00:00\u0026lt;00:00, 2.12MB/s]"}},"9e32449cd53b47f7bfbea13e90ff197a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a67f96ed129243ceb8c862bf8310e4c5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aad18d3eb6d24bd98e3613722f1dbe30":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"abe264cc15ef4c1e9335add4a346901e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac8e81b943844f639839b06f8da98586":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b012a2ea780d4e26a53681bfcbf1e1fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b21bdaf1dbdc4a9c8b5825f928fee7d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb539d78ff174cd68047a462fd3b35fc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf14ba927e8a4b3d83cad511d230098c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_31bfb35ba4254018ba5dd8c52c70cb63","placeholder":"​","style":"IPY_MODEL_d57cd2209e634af0a41c49fbcd1c172d","value":" 32332/32332 [00:00\u0026lt;00:00, 356538.78 examples/s]"}},"c617b8a685c042c698f5a5543d63b24b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6335f582d21d46dbb3481c76d27de350","max":28064,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cb28dad87d7e4836b6ae58a3ec9589c3","value":28064}},"c879a37add5741d2ad62e631ba5277a2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c93ff8a0466244dc8aec4c761d53b318":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca6e19283e14425e8e538a1dc69bb7dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c5410d301d442df950e84b7985891e0","max":4850,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aad18d3eb6d24bd98e3613722f1dbe30","value":4850}},"cadebe445202422681ebdf9fb68fe213":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e4c2083395344fe8175358d2a72c78b","placeholder":"​","style":"IPY_MODEL_1bfe8387c7fb4389b7ac80f653292c4a","value":"Validation DataLoader 0: 100%"}},"cb28dad87d7e4836b6ae58a3ec9589c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cb4c21c818af4b719a7a2fc3bc93c728":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cf6f3aa1203f46e6a1551a690604ae17","IPY_MODEL_75426bb858944ebf875e40ceefeee0a3","IPY_MODEL_3d5d95409f264505a69cddcf9927420d"],"layout":"IPY_MODEL_abe264cc15ef4c1e9335add4a346901e"}},"cf6f3aa1203f46e6a1551a690604ae17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c879a37add5741d2ad62e631ba5277a2","placeholder":"​","style":"IPY_MODEL_4ef3d9b65fbd4767b95c1840842520d7","value":"Downloading data: 100%"}},"d57cd2209e634af0a41c49fbcd1c172d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7f08643067f490ca575b457bea6d9f3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9a59ce8cfffe438296419cb4a4082537","IPY_MODEL_0eff4dd905f24570b871c0dca2244852","IPY_MODEL_3e7a86cb92a64a6cb0e61cf3f2f75f12"],"layout":"IPY_MODEL_45bbfcfaa9c84526ab27f13f8556a07f"}},"dbd61dd727754e3ba398a50b6510d187":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de0e4b73aaa8431ab06566f76d40d9c0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ede7e31213ae422a8bda27a71bff15dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f347a85b87a4455f831360a2b6de35eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6741ad97ba0d49369f48babce42d2550","IPY_MODEL_ca6e19283e14425e8e538a1dc69bb7dd","IPY_MODEL_433eb409262e41919d6814d4d66f42b3"],"layout":"IPY_MODEL_1ffa9ae1f722483daddadf148ec71e88"}},"f9766e4aa3804feba44f7eaf99b4d349":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb7016caa05a4c8689a3ab78a579f76a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe5d151a7a3e478f96cee0a7def507b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb539d78ff174cd68047a462fd3b35fc","placeholder":"​","style":"IPY_MODEL_c93ff8a0466244dc8aec4c761d53b318","value":"Generating train split: 100%"}}}}},"nbformat":4,"nbformat_minor":0}